[extractors]
words: type=WholeWordFeatureExtractor extract_e=True extract_f=True extract_ef=True
affixes: type=AffixFeatureExtractor extract_e=False extract_f=False extract_ef=True suffix_sizes=[2,3] prefix_sizes=[]
categories: type=CategoryFeatureExtractor extract_e=True extract_f=True extract_ef=True 
jumpfeatures: type=JumpFeatureExtractor bins=[1,2,3,4,5,6]
distfeatures: type=DistortionFeatureExtractor

[components]
udist: type=UniformAlignment
llLexical: type=LogLinearLexical init='uniform' sgd-steps=5 sgd-attempts=10 extractors=['words']
jump: type=VogelJump
# This is a log-linear version of Vogel's jump distribution
llJump: type=LogLinearJump init='uniform' sgd-steps=5 sgd-attempts=5 extractors=['jumpfeatures']
# This is a log-linear version of Brown's distortion distribution
#llDist: type=LogLinearDistortion init='uniform' sgd-steps=5 sgd-attempts=5 extractors=['distfeatures']

[models]

# log linear lexical component
llibm1: iterations=10 components=['llLexical','udist']
# + Vogel's jump distribution
llibm2: iterations=10 components=['llLexical','jump']
# alternatively, we can use log linear alignment distributions as well
# such as a log linear version of Vogel's 
#llibm2: iterations=10 components=['llLexical','llJump']
# or a log linear version of Brown's
#llibm2: iterations=10 components=['llLexical','llDist']


